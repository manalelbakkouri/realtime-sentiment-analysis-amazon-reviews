version: '3.8'

services:
  zookeeper:
    image: bitnami/zookeeper:3.8
    container_name: Backend_zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - bigdata-net

  kafka:
    image: bitnami/kafka:3.4
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENERS=PLAINTEXT_INTERNAL://:9092,PLAINTEXT_EXTERNAL://:29092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT_INTERNAL://kafka:9092,PLAINTEXT_EXTERNAL://localhost:29092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT_INTERNAL
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--list", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 20s
      retries: 10
    depends_on:
      - zookeeper
    networks:
      - bigdata-net

  mongodb:
    image: mongo:latest
    container_name: Backend_mongodb
    ports:
      - "27017:27017"
    volumes:
      - ./data/mg_db:/data/db
    networks:
      - bigdata-net

  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077"
      - "8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
    networks:
      - bigdata-net

  spark-worker:
    image: bitnami/spark:3.5
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master
    networks:
      - bigdata-net

  producer:
    build:
      context: ./scripts/produce_file
    container_name: Backend-producer
    volumes:
      - ./data:/data
    environment:
      - KAFKA_BROKER=kafka:9092
      - TOPIC_NAME=topic_raw
    depends_on:
      - kafka
    networks:
      - bigdata-net

  cleaning_stream:
    build:
      context: ./scripts/cleaning_stream
    container_name: cleaning_stream
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - kafka
      - spark-master
    networks:
      - bigdata-net

  spark_consumer:
    build:
      context: ./scripts/spark_consumer
    container_name: spark_consumer
    volumes:
      - ./scripts/spark_consumer/models/sentiment_model:/app/models/sentiment_model
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - kafka
      - spark-master
    networks:
      - bigdata-net

  store_predictions:
    build:
      context: ./scripts/store_predictions
    container_name: store_predictions
    environment:
      - KAFKA_BROKER=kafka:9092
      - MONGO_URI=mongodb://mongodb:27017
      - DB_NAME=sentiment_analysis
      - COLLECTION_NAME=predictions
    depends_on:
      - mongodb
      - kafka
    networks:
      - bigdata-net

  flask-backend:
    build:
      context: .
    container_name: flask-backend
    command: python -m flask run --host=0.0.0.0 --port=5000
    ports:
      - "5000:5000"
    volumes:
      - .:/app
    environment:
      - FLASK_APP=scripts/app.py
      - FLASK_ENV=development
      - MONGO_URI=mongodb://mongodb:27017
      - DB_NAME=sentiment_analysis
      - COLLECTION_NAME=predictions
      - DOCKERIZED=true
    depends_on:
      - mongodb
    networks:
      - bigdata-net

  frontend:
    build:
      context: ../Frontend/frontend
    container_name: frontend
    ports:
      - "3000:3000"
    networks:
      - bigdata-net

networks:
  bigdata-net:
    driver: bridge

